{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning for Time Series \n",
    "\n",
    "Deep Learning is a subset of machine learning and excels when dealing with large and complex data, as it can extract complex features with minimal human involvement. Deep learning works well with structured and unstructured data and can be used in supervised, unsupervised and semi-supervised learning. \n",
    "\n",
    "This chapter focuses on using deep learning for time series forecasting - using different deep learning architectures suitable for sequential data such as time series data. There are different deep learning architectures for solving various problems: \n",
    "\n",
    "* Recurrent Neural Networks (RNNs)\n",
    "* Long-Short Term Memory (LSTM)\n",
    "* Gated Recurrent Unit (GRU)\n",
    "* Convolutional Neural Networks (CNNs)\n",
    "* Autoencoders\n",
    "* Generative Adversarial Networks (GANs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Standardize:\n",
    "    def __init__(self, df, split=0.10):\n",
    "        self.data = df \n",
    "        self.split = split \n",
    "\n",
    "    def split_data(self):\n",
    "        n = int(len(self.data) * self.split)\n",
    "        train, test = self.data.iloc[:-n], self.data.iloc[-n:]\n",
    "        n = int(len(train) * self.split)\n",
    "        train, val = train.iloc[:-n], train.iloc[-n:]\n",
    "        assert len(test) + len(train) + len(val) == len(self.data)\n",
    "        return train, test, val \n",
    "    \n",
    "    def _transform(self, data):\n",
    "        data_s = (data - self.mu)/self.sigma \n",
    "        return data_s \n",
    "    \n",
    "    def fit_transform(self):\n",
    "        train, test, val = self.split_data()\n",
    "        self.mu, self.sigma = train.mean(), train.std()\n",
    "        train_s = self._transform(train)\n",
    "        test_s = self._transform(test)\n",
    "        val_s = self._transform(val)\n",
    "        return train_s, test_s, val_s \n",
    "    \n",
    "    def inverse(self, data):\n",
    "        return (data * self.sigma)+self.mu \n",
    "    \n",
    "    def inverse_y(self, data):\n",
    "        return (data * self.sigma[-1])+self.mu[-1]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_step_forecast(df, window):\n",
    "    d = df.values \n",
    "    x = []\n",
    "    n = len(df)\n",
    "    idx = df.index[:-window]\n",
    "    for start in range(n-window):\n",
    "        end = start + window\n",
    "        x.append(d[start:end])\n",
    "    cols = [f'x_{i}' for i in range(1, window+1)]\n",
    "    x = np.array(x).reshape(n-window, -1)\n",
    "    y = df.iloc[window:].values\n",
    "    df_xs = pd.DataFrame(x, columns=cols, index=idx)\n",
    "    df_y = pd.DataFrame(y.reshape(-1), columns=['y'], index=idx)\n",
    "\n",
    "    return pd.concat([df_y, df_xs], axis=1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example \n",
    "\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "from pathlib import Path \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "path = Path('../TimeSeriesAnalysisWithPythonCookbook/Data/')\n",
    "energy = pd.read_csv(path.joinpath('energy_consumption.csv'), index_col='Month', parse_dates=True)\n",
    "energy.columns = ['y']\n",
    "energy.index.freq = 'MS'\n",
    "en_df = one_step_forecast(energy, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data using the updated Standardize class \n",
    "scale_en = Standardize(en_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_en, test_en, val_en = scale_en.fit_transform()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Learning libraries can be broken down into either **low-level, high-level** or both. High-level libraries allow for quick prototyping and experimentation when testing various architectures, such as the case with Keras. A low-level library gives us more flexibility and control, but we will have to define more aspects of a model's architecture - PyTorch and Tensorflow are examples of low-level libraries. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting with an RNN using Keras \n",
    "\n",
    "RNNs initially entered the spotlight with NLP, as they were designed for sequential data, where past observations, such as words, have a strong influence on determining the next word in a sentence. This need for the artificial neural network to retain memory (hidden state) inspired the RNN architecture. Similarly, time series data is also sequential, and since past observations influece future observations, it also needs a network with memory. \n",
    "\n",
    "In RNNs, there is a feedback loop where the output of one node or neuron is fed back (the recursive part) as input, allowing the network to learn from a prior time step acting as a memory. \n",
    "\n",
    "In an RNN we have two outputs and two sets of weights: $W_{X}$ for the input and $W_{H}$ for the hidden state or memory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.compat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mg:\\My Drive\\Projekter\\Statistics\\Training\\TimeSeriesAnalysisWithPythonCookbook\\Ch13.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/My%20Drive/Projekter/Statistics/Training/TimeSeriesAnalysisWithPythonCookbook/Ch13.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m \n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/My%20Drive/Projekter/Statistics/Training/TimeSeriesAnalysisWithPythonCookbook/Ch13.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m#import keras \u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/My%20Drive/Projekter/Statistics/Training/TimeSeriesAnalysisWithPythonCookbook/Ch13.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n",
      "File \u001b[1;32mc:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\__init__.py:21\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[39mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n\u001b[1;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m models\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minput_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m Input\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequential\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n",
      "File \u001b[1;32mc:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\models\\__init__.py:18\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"Keras models API.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mimport\u001b[39;00m Functional\n\u001b[0;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequential\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtraining\u001b[39;00m \u001b[39mimport\u001b[39;00m Model\n",
      "File \u001b[1;32mc:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\engine\\functional.py:24\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mitertools\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdtensor\u001b[39;00m \u001b[39mimport\u001b[39;00m layout_map \u001b[39mas\u001b[39;00m layout_map_lib\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.compat'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "#import keras \n",
    "from keras.models import Sequential\n",
    "#keras.models.Sequential\n",
    "#import tf.keras.models.Sequential \n",
    "\n",
    "# import Sequential \n",
    "#from tensorflow import keras \n",
    "# from tensorflow.keras.metrics import RootMeanSquaredError, MeanAbsoluteError \n",
    "# from keras.layers import Dense, SimpleRnn, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the features_target_ts function that takes a dataset and returns an x split \n",
    "# (independent variables or features) and y split (dependent or target variables)\n",
    "\n",
    "def features_target_ts(*args):\n",
    "    y = [col.pop('y').values.reshape(-1,1) for col in args]\n",
    "    x = [col.values.reshape(*col.shape, 1) for col in args]\n",
    "\n",
    "    return *y, *x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can pass the train, test and validation sets to the features_target_ts function and\n",
    "# it will return six splits\n",
    "\n",
    "(y_train_en, y_val_en, y_test_en, x_train_en, x_val_en, x_test_en) = features_target_ts(train_en, val_en, test_en)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the create_model function, which is used to construct the network's architecture.\n",
    "# The Sequential class will sequentially add or stack the different layers in the order added,\n",
    "# hence the name. We will implement the SimpleRNN architecture \n",
    "\n",
    "def create_model(train, units, dropout=0.2):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.models.SimpleRNN(units=units, \n",
    "                        return_sequences=False,\n",
    "                        input_shape=(train.shape[1], \n",
    "                                     train.shape[2])))\n",
    "    model.add(tf.keras.metrics.Dropout(dropout))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    return model \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The create_model function will return a Sequential object which contains the architecture (the layers and the configuration). We are adding a dropout layer that randomly drops some of the unity by setting them to zero. The frequency is set at 0.2 (20%), indicating the fraction of the input units to drop. return_sequence is set to False, indicating that only the last output is returned\n",
    "\n",
    "Create the train_model_ts function, which takes as input the returned Sequential object (which we are calling model), and the training and validation sets. The function will compile and train the model on the training sets and use the validation sets for evaluation at each epoch, displaying the scores against the training and validation sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_ts(model, x_train, y_train, x_val, y_val, epochs=500, patience=12, batch_size=32):\n",
    "    model.compile(optimizer=\"adam\", \n",
    "                  loss='mean_squared_error', \n",
    "                  metrics=[RootMeanSquaredError(), \n",
    "                           MeanAbsoluteError()])\n",
    "    \n",
    "    es = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\", \n",
    "        min_delta=0, \n",
    "        patience=patience)\n",
    "    \n",
    "    history = model.fit(x_train, y_train, \n",
    "                        shuffle=False, epochs=epochs, \n",
    "                        batch_size=batch_size, \n",
    "                        validation_data = (x_val, y_val), \n",
    "                        callbacks=[es], verbose=1)\n",
    "    \n",
    "    return history\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function will return the history object, which is a Python dictionary that includes all the scores captured at each epoch for the training and validation sets\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the plot_forecast function, which will take the model object to make a prediction (forecast) and print out the predicted values against the actual values (out-of-sample) in the test set. Additionally, the function takes the history dictionary to plot the model's performance during training, so we can visually evaluate the model for any signs of overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_forecast(model, x_test, y_test, index, history):\n",
    "    fig, ax = plt.subplots(2, 1)\n",
    "    (pd.Series(history.history['loss']).plot(style='k', alpha=0.5, title='Loss by Epoch',\n",
    "           ax = ax[0], label='loss'))\n",
    "    \n",
    "    (pd.Series(history.history['val_loss']).plot(style='k', ax=ax[0], label='val_loss'))\n",
    "    ax[0].legend()\n",
    "    predicted = model.predict(x_test)\n",
    "    pd.Series(y_test.reshape(-1), \n",
    "              index=index).plot(style='k--', alpha=0.5, ax=ax[1], title=\"Forecast vs Actual\", label='actual')\n",
    "    pd.Series(predicted.reshape(-1), \n",
    "              index=index).plot(style='k', label='Forecast', ax=ax[1])\n",
    "    fig.tight_layout()\n",
    "    ax[1].legend()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function displays two subplots - the first plot will contain the performance during training (training and validation loss) and the bottom chart will compare the forecast. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mg:\\My Drive\\Projekter\\Statistics\\Training\\TimeSeriesAnalysisWithPythonCookbook\\Ch13.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/My%20Drive/Projekter/Statistics/Training/TimeSeriesAnalysisWithPythonCookbook/Ch13.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Use the create_model function to create the Sequential object\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/My%20Drive/Projekter/Statistics/Training/TimeSeriesAnalysisWithPythonCookbook/Ch13.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model_en_simpleRNN \u001b[39m=\u001b[39m create_model(x_train_en, units\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m)\n",
      "\u001b[1;32mg:\\My Drive\\Projekter\\Statistics\\Training\\TimeSeriesAnalysisWithPythonCookbook\\Ch13.ipynb Cell 19\u001b[0m in \u001b[0;36mcreate_model\u001b[1;34m(train, units, dropout)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/My%20Drive/Projekter/Statistics/Training/TimeSeriesAnalysisWithPythonCookbook/Ch13.ipynb#X25sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_model\u001b[39m(train, units, dropout\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/My%20Drive/Projekter/Statistics/Training/TimeSeriesAnalysisWithPythonCookbook/Ch13.ipynb#X25sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39mSequential()\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/My%20Drive/Projekter/Statistics/Training/TimeSeriesAnalysisWithPythonCookbook/Ch13.ipynb#X25sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     model\u001b[39m.\u001b[39madd(tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mSimpleRNN(units\u001b[39m=\u001b[39munits, \n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/My%20Drive/Projekter/Statistics/Training/TimeSeriesAnalysisWithPythonCookbook/Ch13.ipynb#X25sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                         return_sequences\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/My%20Drive/Projekter/Statistics/Training/TimeSeriesAnalysisWithPythonCookbook/Ch13.ipynb#X25sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                         input_shape\u001b[39m=\u001b[39m(train\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], \n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Projekter/Statistics/Training/TimeSeriesAnalysisWithPythonCookbook/Ch13.ipynb#X25sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                                      train\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m])))\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Projekter/Statistics/Training/TimeSeriesAnalysisWithPythonCookbook/Ch13.ipynb#X25sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     model\u001b[39m.\u001b[39madd(tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mDropout(dropout))\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'keras'"
     ]
    }
   ],
   "source": [
    "# Use the create_model function to create the Sequential object\n",
    "\n",
    "model_en_simpleRNN = create_model(x_train_en, units=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
